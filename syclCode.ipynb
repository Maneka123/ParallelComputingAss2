{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "507dc31e-864f-4614-a2e4-c7c447163dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing lab/code1.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile lab/code1.cpp\n",
    "//==============================================================\n",
    "// Copyright © Intel Corporation\n",
    "//\n",
    "// SPDX-License-Identifier: MIT\n",
    "// =============================================================\n",
    "#include <sycl/sycl.hpp>\n",
    "\n",
    "using namespace sycl;\n",
    "\n",
    "#include <CL/sycl.hpp>\n",
    "#include <iostream>\n",
    "#include <CL/sycl.hpp>\n",
    "#include <CL/sycl.hpp>\n",
    "#include <iostream>\n",
    "\n",
    "\n",
    "#include <CL/sycl.hpp>\n",
    "#include <chrono>\n",
    "#include <iostream>\n",
    "#include <thread>\n",
    "#include <cstdlib>\n",
    "\n",
    "const int n = 3;  // Number of features\n",
    "const int m = 5;  // Number of data points\n",
    "\n",
    "using namespace sycl;\n",
    "\n",
    "// Define matrix-vector multiplication function with transpose using SYCL\n",
    "void matrix_vector_multiply_transpose(const float X[], float X_T[], const float w[], float res[], int m, int n, queue &q) {\n",
    "    auto R = range<2>(m, n);\n",
    "    auto A = buffer<float, 2>(X, R);  // Buffer for input matrix X\n",
    "    auto AT = buffer<float, 2>(X_T, R);  // Buffer for transpose\n",
    "    auto W = buffer<float, 1>(w, range<1>(n));\n",
    "    auto Result = buffer<float, 1>(res, range<1>(m));\n",
    "\n",
    "    q.submit([&](handler &cgh) {\n",
    "        auto X_acc = A.get_access<access::mode::read>(cgh);\n",
    "        auto X_T_acc = AT.get_access<access::mode::write>(cgh);\n",
    "        auto w_acc = W.get_access<access::mode::read>(cgh);\n",
    "        auto res_acc = Result.get_access<access::mode::write>(cgh);\n",
    "\n",
    "        cgh.parallel_for(R, [=](id<2> index) {\n",
    "            int i = index[0];\n",
    "            int j = index[1];\n",
    "            X_T_acc[index] = X_acc[cl::sycl::id<2>(j, i)]; // Transpose matrix\n",
    "        });\n",
    "    });\n",
    "    q.wait();\n",
    "}\n",
    "\n",
    "// Define element-wise vector subtraction function using SYCL\n",
    "void subtract_vectors(const float vec1[], float res2[], int m, queue &q) {\n",
    "    auto R = range<1>(m);\n",
    "    auto V1 = buffer<float, 1>(vec1, R);\n",
    "    auto Res = buffer<float, 1>(res2, R);\n",
    "\n",
    "    q.submit([&](handler &cgh) {\n",
    "        auto v1_acc = V1.get_access<access::mode::read>(cgh);\n",
    "        auto res_acc = Res.get_access<access::mode::write>(cgh);\n",
    "\n",
    "        cgh.parallel_for(R, [=](id<1> index) {\n",
    "            res_acc[index] -= v1_acc[index];\n",
    "        });\n",
    "    });\n",
    "    q.wait();\n",
    "}\n",
    "\n",
    "// Calculate the norm of a vector using SYCL\n",
    "float calculate_vector_norm(const float v[], int n, queue &q) {\n",
    "    auto R = range<1>(n);\n",
    "    auto V = buffer<float, 1>(v, R);\n",
    "\n",
    "    auto result = buffer<float, 1>(range<1>(1));\n",
    "\n",
    "    q.submit([&](handler &cgh) {\n",
    "        auto v_acc = V.get_access<access::mode::read>(cgh);\n",
    "        auto result_acc = result.get_access<access::mode::discard_write>(cgh);\n",
    "\n",
    "        cgh.parallel_for(R, [=](id<1> index) {\n",
    "            result_acc[0] += v_acc[index] * v_acc[index];\n",
    "        });\n",
    "    });\n",
    "    q.wait();\n",
    "\n",
    "    float v_norm = 0.0f;\n",
    "    auto result_acc = result.get_access<access::mode::read>();\n",
    "    v_norm = std::sqrt(result_acc[0]);\n",
    "\n",
    "    return v_norm;\n",
    "}\n",
    "\n",
    "// Function to perform your computation\n",
    "void performComputation(queue &q) {\n",
    "    float X[15] = {\n",
    "        1.0f, 2.0f, 3.0f,\n",
    "        4.0f, 5.0f, 6.0f,\n",
    "        7.0f, 8.0f, 9.0f,\n",
    "        10.0f, 11.0f, 12.0f,\n",
    "        13.0f, 14.0f, 15.0f\n",
    "    };\n",
    "\n",
    "    float X_T[15] = {0.0f};  // Initialize to zeros\n",
    "    float w[3] = {0.1f, 0.1f, 0.1f};\n",
    "    float res[5] = {0.0f};\n",
    "    float Y[5] = {0.0f, 1.0f, 0.0f, 1.0f, 1.0f};\n",
    "    float gradient_update[3];  // Define gradient_update here\n",
    "\n",
    "    float alpha = 0.05f;  // Learning rate\n",
    "    int max_iterations = 10;\n",
    "    int iteration = 0;\n",
    "    float epsilon_sq = 0.001f * 0.001f;\n",
    "\n",
    "    while (1) {\n",
    "        matrix_vector_multiply_transpose(X, X_T, w, res, m, n, q);\n",
    "\n",
    "        for (int i = 0; i < m; i++) {\n",
    "            res[i] = 1.0f / (1.0f + std::exp(-res[i]));\n",
    "        }\n",
    "\n",
    "        // Calculate gradient and update weights\n",
    "        matrix_vector_multiply_transpose(X, X_T, res, gradient_update, m, n, q);\n",
    "        float gradient[n];\n",
    "        for (int i = 0; i < n; i++) {\n",
    "            gradient[i] = gradient_update[i];\n",
    "        }\n",
    "\n",
    "        // Subtract vectors here\n",
    "        subtract_vectors(Y, res, m, q);\n",
    "\n",
    "        for (int i = 0; i < n; i++) {\n",
    "            w[i] -= alpha * gradient[i];\n",
    "        }\n",
    "        \n",
    "        // Print the updated weight vector\n",
    "        std::cout << \"Iteration \" << iteration << \" - Updated Weight Vector (w*):\\n\";\n",
    "        for (int i = 0; i < n; i++) {\n",
    "            std::cout << w[i] << \" \";\n",
    "        }\n",
    "        std::cout << std::endl;\n",
    "\n",
    "        // Calculate the gradient norm\n",
    "        float grad_norm = calculate_vector_norm(gradient, n, q);\n",
    "\n",
    "        // Check the termination conditions\n",
    "        if (grad_norm * grad_norm <= epsilon_sq || iteration >= max_iterations) {\n",
    "            break;\n",
    "        }\n",
    "\n",
    "        iteration++;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const int maxCores = 8;  // Set the maximum number of CPU cores to test\n",
    "\n",
    "    for (int numCores = 1; numCores <= maxCores; numCores++) {\n",
    "        std::cout << \"Number of CPU cores: \" << numCores << std::endl;\n",
    "\n",
    "        // Set the number of CPU cores explicitly using 'OMP_NUM_THREADS' environment variable\n",
    "        std::string envVarName = \"OMP_NUM_THREADS\";\n",
    "        std::string envVarValue = std::to_string(numCores);\n",
    "        if (setenv(envVarName.c_str(), envVarValue.c_str(), 1) != 0) {\n",
    "            std::cerr << \"Error setting environment variable.\" << std::endl;\n",
    "            return 1;\n",
    "        }\n",
    "\n",
    "        auto start = std::chrono::high_resolution_clock::now();\n",
    "\n",
    "        // Create a SYCL queue without specifying in-order property\n",
    "        queue q;\n",
    "\n",
    "        // Perform your computation\n",
    "        performComputation(q);\n",
    "\n",
    "        auto end = std::chrono::high_resolution_clock::now();\n",
    "        std::chrono::duration<double> duration = end - start;\n",
    "        std::cout << \"Time: \" << duration.count() << \" seconds\" << std::endl;\n",
    "    }\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d55795-6bbe-4b1d-9108-4a69674fc43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 755 q; chmod 755 run_simple2.sh;if [ -x \"$(command -v qsub)\" ]; then ./q run_simple2.sh; else ./run_simple2.sh; fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826c543b-cc29-4d7e-acd6-996373a09be4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Intel® oneAPI 2023.2)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
