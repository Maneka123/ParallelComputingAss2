{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pV7pkuXqHlF",
        "outputId": "9df4968e-f3a1-4e62-ccd4-d7adc3654ec9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting code4.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile code4.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <stdio.h>\n",
        "#include <math.h>\n",
        "#include <omp.h> // Include the OpenMP library\n",
        "\n",
        "__global__ void matrixVectorMultiplyWithSigmoid(double *d_X, double *d_vector, double *d_result) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < 5) {\n",
        "        double sum = 0.0;\n",
        "        for (int j = 0; j < 3; j++) {\n",
        "            sum += d_X[idx * 3 + j] * d_vector[j];\n",
        "        }\n",
        "        // Apply sigmoid to the sum\n",
        "        d_result[idx] = 1.0 / (1.0 + exp(-sum));\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void subtractArrays(double *d_result, double *d_Y) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < 5) {\n",
        "        d_result[idx] -= d_Y[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void multiplyTransposedMatrix(double *d_X, double *d_result, double *d_gradient_update) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < 3) {\n",
        "        double product = 0.0;\n",
        "        for (int j = 0; j < 5; j++) {\n",
        "            product += d_result[j] * d_X[j * 3 + idx];\n",
        "        }\n",
        "        d_gradient_update[idx] = product;\n",
        "    }\n",
        "}\n",
        "\n",
        "double calculateL2Norm(double *v, int n) {\n",
        "    double norm = 0.0;\n",
        "\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        norm += v[i] * v[i];\n",
        "    }\n",
        "\n",
        "    // Take the square root to get the L2 norm\n",
        "    norm = sqrt(norm);\n",
        "\n",
        "    return norm;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    double X[5][3] = {\n",
        "        {1.0, 2.0, 3.0},\n",
        "        {4.0, 5.0, 6.0},\n",
        "        {7.0, 8.0, 9.0},\n",
        "        {10.0, 11.0, 12.0},\n",
        "        {13.0, 14.0, 15.0}\n",
        "    };\n",
        "    double vector[3] = {0.1, 0.1, 0.1};\n",
        "    double result[5];\n",
        "    double Y[5] = {0.0, 1.0, 0.0, 1.0, 1.0};\n",
        "    double gradient_update[3];\n",
        "    double gradient[3];\n",
        "    double w[3] = {0.1, 0.1, 0.1};\n",
        "    double alpha = 0.05;\n",
        "    int n = 3;\n",
        "    int iteration = 0;\n",
        "    int max_iterations = 10;\n",
        "    double epsilon = 0.001;\n",
        "    double epsilon_sq = epsilon * epsilon;\n",
        "\n",
        "    double *d_X, *d_vector, *d_result, *d_Y, *d_gradient_update;\n",
        "    cudaMalloc((void **)&d_X, 5 * 3 * sizeof(double));\n",
        "    cudaMalloc((void **)&d_vector, 3 * sizeof(double));\n",
        "    cudaMalloc((void **)&d_result, 5 * sizeof(double));\n",
        "    cudaMalloc((void **)&d_Y, 5 * sizeof(double));\n",
        "    cudaMalloc((void **)&d_gradient_update, 3 * sizeof(double));\n",
        "\n",
        "\n",
        "    cudaMemcpy(d_X, X, 5 * 3 * sizeof(double), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_vector, vector, 3 * sizeof(double), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_Y, Y, 5 * sizeof(double), cudaMemcpyHostToDevice);\n",
        "\n",
        "    const int maxCores = 8; // Set the maximum number of CPU cores to test\n",
        "\n",
        "    for (int numCores = 1; numCores <= maxCores; numCores++) {\n",
        "        // Set the number of threads for parallel processing\n",
        "        omp_set_num_threads(numCores);\n",
        "\n",
        "        double start_time = omp_get_wtime(); // Get the start time\n",
        "\n",
        "        // Calculate the number of threads per block and the number of blocks\n",
        "        dim3 threadsPerBlock(256);\n",
        "        dim3 numBlocks((5 + threadsPerBlock.x - 1) / threadsPerBlock.x);\n",
        "\n",
        "        while (true) {\n",
        "            matrixVectorMultiplyWithSigmoid<<<numBlocks, threadsPerBlock>>>(d_X, d_vector, d_result);\n",
        "            cudaDeviceSynchronize();\n",
        "\n",
        "            subtractArrays<<<numBlocks, threadsPerBlock>>>(d_result, d_Y);\n",
        "            cudaDeviceSynchronize();\n",
        "\n",
        "            multiplyTransposedMatrix<<<1, 3>>>(d_X, d_result, d_gradient_update);\n",
        "            cudaDeviceSynchronize();\n",
        "\n",
        "            cudaMemcpy(result, d_result, 5 * sizeof(double), cudaMemcpyDeviceToHost);\n",
        "            cudaMemcpy(gradient_update, d_gradient_update, 3 * sizeof(double), cudaMemcpyDeviceToHost);\n",
        "\n",
        "            // Copy the content from gradient_update to gradient\n",
        "            cudaMemcpy(gradient, d_gradient_update, 3 * sizeof(double), cudaMemcpyDeviceToHost);\n",
        "\n",
        "            // Print the updated result\n",
        "            printf(\"Updated Result:\\n\");\n",
        "            for (int i = 0; i < 5; i++) {\n",
        "                printf(\"%.5f \", result[i]);\n",
        "            }\n",
        "            printf(\"\\n\");\n",
        "\n",
        "            // Print the gradient\n",
        "            printf(\"Gradient:\\n\");\n",
        "            for (int i = 0; i < 3; i++) {\n",
        "                printf(\"%.2f \", gradient[i]);\n",
        "            }\n",
        "            printf(\"\\n\");\n",
        "\n",
        "            // Update the weight vector\n",
        "            for (int i = 0; i < 3; i++) {\n",
        "                w[i] -= alpha * gradient[i];\n",
        "            }\n",
        "\n",
        "            // Print the updated weight vector\n",
        "            printf(\"Updated Weight Vector:\\n\");\n",
        "            for (int i = 0; i < 3; i++) {\n",
        "                printf(\"%.2f \", w[i]);\n",
        "            }\n",
        "            printf(\"\\n\");\n",
        "\n",
        "            double l2Norm = calculateL2Norm(gradient, n);\n",
        "\n",
        "            printf(\"L2 Norm: %.5f\\n\", l2Norm);\n",
        "\n",
        "            if (l2Norm * l2Norm <= epsilon_sq) {\n",
        "                break;\n",
        "            }\n",
        "\n",
        "            if (iteration >= max_iterations) {\n",
        "                break;\n",
        "            }\n",
        "\n",
        "            iteration++;\n",
        "        }\n",
        "\n",
        "        double end_time = omp_get_wtime(); // Get the end time\n",
        "        double elapsed_time = end_time - start_time;\n",
        "\n",
        "        // Print the number of CPU cores and the elapsed time\n",
        "        std::cout << \"Number of CPU cores: \" << numCores << std::endl;\n",
        "        std::cout << \"Elapsed time: \" << elapsed_time << \" seconds\" << std::endl;\n",
        "    }\n",
        "\n",
        "    cudaFree(d_X);\n",
        "    cudaFree(d_vector);\n",
        "    cudaFree(d_result);\n",
        "    cudaFree(d_Y);\n",
        "    cudaFree(d_gradient_update);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! nvcc code4.cu -o code4.o -Xcompiler -fopenmp"
      ],
      "metadata": {
        "id": "-MEqGlhRqP9c"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ./code4.o"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S83XA3lSqQHN",
        "outputId": "5d9cbe32-cb36-46a3-cc0d-aac9d7ec4cf0"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated Result:\n",
            "0.64566 -0.18243 0.91683 -0.03557 -0.01477 \n",
            "Gradient:\n",
            "5.79 7.12 8.45 \n",
            "Updated Weight Vector:\n",
            "-0.19 -0.26 -0.32 \n",
            "L2 Norm: 12.46736\n",
            "Updated Result:\n",
            "0.64566 -0.18243 0.91683 -0.03557 -0.01477 \n",
            "Gradient:\n",
            "5.79 7.12 8.45 \n",
            "Updated Weight Vector:\n",
            "-0.48 -0.61 -0.74 \n",
            "L2 Norm: 12.46736\n",
            "Updated Result:\n",
            "0.64566 -0.18243 0.91683 -0.03557 -0.01477 \n",
            "Gradient:\n",
            "5.79 7.12 8.45 \n",
            "Updated Weight Vector:\n",
            "-0.77 -0.97 -1.17 \n",
            "L2 Norm: 12.46736\n",
            "Updated Result:\n",
            "0.64566 -0.18243 0.91683 -0.03557 -0.01477 \n",
            "Gradient:\n",
            "5.79 7.12 8.45 \n",
            "Updated Weight Vector:\n",
            "-1.06 -1.32 -1.59 \n",
            "L2 Norm: 12.46736\n",
            "Updated Result:\n",
            "0.64566 -0.18243 0.91683 -0.03557 -0.01477 \n",
            "Gradient:\n",
            "5.79 7.12 8.45 \n",
            "Updated Weight Vector:\n",
            "-1.35 -1.68 -2.01 \n",
            "L2 Norm: 12.46736\n",
            "Updated Result:\n",
            "0.64566 -0.18243 0.91683 -0.03557 -0.01477 \n",
            "Gradient:\n",
            "5.79 7.12 8.45 \n",
            "Updated Weight Vector:\n",
            "-1.64 -2.03 -2.43 \n",
            "L2 Norm: 12.46736\n",
            "Updated Result:\n",
            "0.64566 -0.18243 0.91683 -0.03557 -0.01477 \n",
            "Gradient:\n",
            "5.79 7.12 8.45 \n",
            "Updated Weight Vector:\n",
            "-1.93 -2.39 -2.86 \n",
            "L2 Norm: 12.46736\n",
            "Updated Result:\n",
            "0.64566 -0.18243 0.91683 -0.03557 -0.01477 \n",
            "Gradient:\n",
            "5.79 7.12 8.45 \n",
            "Updated Weight Vector:\n",
            "-2.21 -2.75 -3.28 \n",
            "L2 Norm: 12.46736\n",
            "Updated Result:\n",
            "0.64566 -0.18243 0.91683 -0.03557 -0.01477 \n",
            "Gradient:\n",
            "5.79 7.12 8.45 \n",
            "Updated Weight Vector:\n",
            "-2.50 -3.10 -3.70 \n",
            "L2 Norm: 12.46736\n",
            "Updated Result:\n",
            "0.64566 -0.18243 0.91683 -0.03557 -0.01477 \n",
            "Gradient:\n",
            "5.79 7.12 8.45 \n",
            "Updated Weight Vector:\n",
            "-2.79 -3.46 -4.12 \n",
            "L2 Norm: 12.46736\n",
            "Updated Result:\n",
            "0.64566 -0.18243 0.91683 -0.03557 -0.01477 \n",
            "Gradient:\n",
            "5.79 7.12 8.45 \n",
            "Updated Weight Vector:\n",
            "-3.08 -3.81 -4.54 \n",
            "L2 Norm: 12.46736\n",
            "Number of CPU cores: 1\n",
            "Elapsed time: 0.0010034 seconds\n",
            "Updated Result:\n",
            "0.64566 -0.18243 0.91683 -0.03557 -0.01477 \n",
            "Gradient:\n",
            "5.79 7.12 8.45 \n",
            "Updated Weight Vector:\n",
            "-3.37 -4.17 -4.97 \n",
            "L2 Norm: 12.46736\n",
            "Number of CPU cores: 2\n",
            "Elapsed time: 8.6922e-05 seconds\n",
            "Updated Result:\n",
            "0.64566 -0.18243 0.91683 -0.03557 -0.01477 \n",
            "Gradient:\n",
            "5.79 7.12 8.45 \n",
            "Updated Weight Vector:\n",
            "-3.66 -4.53 -5.39 \n",
            "L2 Norm: 12.46736\n",
            "Number of CPU cores: 3\n",
            "Elapsed time: 8.7736e-05 seconds\n",
            "Updated Result:\n",
            "0.64566 -0.18243 0.91683 -0.03557 -0.01477 \n",
            "Gradient:\n",
            "5.79 7.12 8.45 \n",
            "Updated Weight Vector:\n",
            "-3.95 -4.88 -5.81 \n",
            "L2 Norm: 12.46736\n",
            "Number of CPU cores: 4\n",
            "Elapsed time: 8.3788e-05 seconds\n",
            "Updated Result:\n",
            "0.64566 -0.18243 0.91683 -0.03557 -0.01477 \n",
            "Gradient:\n",
            "5.79 7.12 8.45 \n",
            "Updated Weight Vector:\n",
            "-4.24 -5.24 -6.23 \n",
            "L2 Norm: 12.46736\n",
            "Number of CPU cores: 5\n",
            "Elapsed time: 8.5111e-05 seconds\n",
            "Updated Result:\n",
            "0.64566 -0.18243 0.91683 -0.03557 -0.01477 \n",
            "Gradient:\n",
            "5.79 7.12 8.45 \n",
            "Updated Weight Vector:\n",
            "-4.53 -5.59 -6.66 \n",
            "L2 Norm: 12.46736\n",
            "Number of CPU cores: 6\n",
            "Elapsed time: 8.9202e-05 seconds\n",
            "Updated Result:\n",
            "0.64566 -0.18243 0.91683 -0.03557 -0.01477 \n",
            "Gradient:\n",
            "5.79 7.12 8.45 \n",
            "Updated Weight Vector:\n",
            "-4.82 -5.95 -7.08 \n",
            "L2 Norm: 12.46736\n",
            "Number of CPU cores: 7\n",
            "Elapsed time: 8.7493e-05 seconds\n",
            "Updated Result:\n",
            "0.64566 -0.18243 0.91683 -0.03557 -0.01477 \n",
            "Gradient:\n",
            "5.79 7.12 8.45 \n",
            "Updated Weight Vector:\n",
            "-5.11 -6.30 -7.50 \n",
            "L2 Norm: 12.46736\n",
            "Number of CPU cores: 8\n",
            "Elapsed time: 8.5694e-05 seconds\n"
          ]
        }
      ]
    }
  ]
}